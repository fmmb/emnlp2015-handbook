We use referential translation machines (RTMs) for predicting translation performance. RTMs pioneer a language independent approach to all similarity tasks and remove the need to access any task or domain specific information or resource. We improve our RTM models with the ParFDA instance selection model{\textasciitilde}\cite{Bicici:FDA54FDA:WMT15}, with additional features for predicting the translation performance, and with improved learning models. We develop RTM models for each WMT15 QET (QET15) subtask and obtain improvements over QET14 results. RTMs achieve top performance in QET15 ranking \$1\$st in document- and sentence-level prediction tasks and \$2\$nd in word-level prediction task.
