The phonotactics of a language describes the ways in which the sounds of the language combine to form possible morphemes and words. Humans can learn phonotactic patterns at the level of abstract classes, generalizing across sounds (e.g., ``words can end in a voiced stop''). Moreover, they rapidly acquire these generalizations, even before they acquire soundspecific patterns. We present a probabilistic model intended to capture this earlyabstraction phenomenon. The model represents both abstract and concrete generalizations in its hypothesis space from the outset of learning. This--combined with a parsimony bias in favor of compact descriptions of the input data--leads the model to favor rapid abstraction in a way similar to human learners.
