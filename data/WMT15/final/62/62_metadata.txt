SubmissionNumber#=%=#62
FinalPaperTitle#=%=#How do Humans Evaluate Machine Translation
ShortPaperTitle#=%=#How do Humans Evaluate Machine Translation
NumberOfPages#=%=#10
CopyrightSigned#=%=#Hassan Sajjad
JobTitle#==#
Organization#==#Qatar Computing Research Institute, Hamad Bin Khalifa University, Doha Qatar
Abstract#==#In this paper, we take a closer look at the MT evaluation process from a
glass-box perspective using eye-tracking. We analyze two aspects of the
evaluation task – the background of evaluators (monolingual or bilingual)
and the sources of information available, and we evaluate them using time and
consistency as criteria. Our findings show that monolinguals are slower but
more consistent than bilinguals, especially when only target language
information is available. When exposed to various sources of information,
evaluators in general take more time and in the case of monolinguals, there is
a drop in consistency. Our findings suggest that to have consistent and cost
effective MT evaluations, it is better to use monolinguals with only target
language information.
Author{1}{Firstname}#=%=#Francisco
Author{1}{Lastname}#=%=#Guzmán
Author{1}{Email}#=%=#fguzman@qf.org.qa
Author{1}{Affiliation}#=%=#Qatar Computing Research Institute
Author{2}{Firstname}#=%=#Ahmed
Author{2}{Lastname}#=%=#Abdelali
Author{2}{Email}#=%=#aabdelali@qf.org.qa
Author{2}{Affiliation}#=%=#Qatar Computing Research Institute
Author{3}{Firstname}#=%=#Irina
Author{3}{Lastname}#=%=#Temnikova
Author{3}{Email}#=%=#irina.temnikova@gmail.com
Author{3}{Affiliation}#=%=#Qatar Computing Research Institute
Author{4}{Firstname}#=%=#Hassan
Author{4}{Lastname}#=%=#Sajjad
Author{4}{Email}#=%=#hsajjad@qf.org.qa
Author{4}{Affiliation}#=%=#Qatar Computing Research Institute
Author{5}{Firstname}#=%=#Stephan
Author{5}{Lastname}#=%=#Vogel
Author{5}{Email}#=%=#svogel@qf.org.qa
Author{5}{Affiliation}#=%=#Qatar Computing Research Institute

==========