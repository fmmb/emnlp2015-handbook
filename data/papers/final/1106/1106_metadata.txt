SubmissionNumber#=%=#1106
FinalPaperTitle#=%=#Online Representation Learning in Recurrent Neural Language Models
ShortPaperTitle#=%=#Online Representation Learning in Recurrent Neural Language Models
NumberOfPages#=%=#6
CopyrightSigned#=%=#Marek Rei
JobTitle#==#
Organization#==#Computer Laboratory, University of Cambridge, 15 JJ Thomson Avenue, Cambridge CB3 0FD, UK
Abstract#==#We investigate an extension of continuous online learning in recurrent neural
network language models. The model keeps a separate vector representation of
the current unit of text being processed and adaptively adjusts it after each
prediction. The initial experiments give promising results, indicating that the
method is able to increase language modelling accuracy, while also decreasing
the parameters needed to store the model along with the computation required at
each step.
Author{1}{Firstname}#=%=#Marek
Author{1}{Lastname}#=%=#Rei
Author{1}{Email}#=%=#marek.rei@cl.cam.ac.uk
Author{1}{Affiliation}#=%=#University of Cambridge

==========