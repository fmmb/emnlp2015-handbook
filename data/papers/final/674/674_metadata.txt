SubmissionNumber#=%=#674
FinalPaperTitle#=%=#Representing Text for Joint Embedding of Text and Knowledge Bases
ShortPaperTitle#=%=#Representing Text for Joint Embedding of Text and Knowledge Bases
NumberOfPages#=%=#11
CopyrightSigned#=%=#Danqi Chen
JobTitle#==#
Organization#==#Danqi Chen
Stanford University
Abstract#==#Models that learn to represent textual and knowledge base relations in the same
continuous latent space are able to perform joint inferences among the two
kinds of relations and obtain high accuracy on knowledge base completion
(Riedel et al, 2013). In this paper we propose a model that captures the
compositional structure of textual relations, and jointly optimizes  entity,
knowledge base, and textual relation representations.  The proposed model
significantly improves performance over a model that does not share parameters
among textual relations with common sub-structure.
Author{1}{Firstname}#=%=#Kristina
Author{1}{Lastname}#=%=#Toutanova
Author{1}{Email}#=%=#kristout@microsoft.com
Author{1}{Affiliation}#=%=#Microsoft Research
Author{2}{Firstname}#=%=#Danqi
Author{2}{Lastname}#=%=#Chen
Author{2}{Email}#=%=#danqi@cs.stanford.edu
Author{2}{Affiliation}#=%=#Stanford University
Author{3}{Firstname}#=%=#Patrick
Author{3}{Lastname}#=%=#Pantel
Author{3}{Email}#=%=#me@patrickpantel.com
Author{3}{Affiliation}#=%=#Microsoft Research
Author{4}{Firstname}#=%=#Hoifung
Author{4}{Lastname}#=%=#Poon
Author{4}{Email}#=%=#hoifung@microsoft.com
Author{4}{Affiliation}#=%=#Microsoft Research
Author{5}{Firstname}#=%=#Pallavi
Author{5}{Lastname}#=%=#Choudhury
Author{5}{Email}#=%=#pallavic@microsoft.com
Author{5}{Affiliation}#=%=#Microsoft Research
Author{6}{Firstname}#=%=#Michael
Author{6}{Lastname}#=%=#Gamon
Author{6}{Email}#=%=#mgamon@microsoft.com
Author{6}{Affiliation}#=%=#Microsoft Research

==========