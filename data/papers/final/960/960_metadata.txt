SubmissionNumber#=%=#960
FinalPaperTitle#=%=#A Comparative Study on Regularization Strategies for Embedding-based Neural Networks
ShortPaperTitle#=%=#A Comparative Study on Regularization Strategies for Embedding-based Neural Networks
NumberOfPages#=%=#6
CopyrightSigned#=%=#Hao Peng
JobTitle#==#
Organization#==#Peking University, #5, Yiheyuan Road, Haidian District, Beijing, 100871, P. R. China
Abstract#==#This paper aims to compare different regularization strategies to address a
common phenomenon, severe overfitting, in embedding-based neural networks for
NLP. We chose two widely studied neural models and tasks as our testbed. We
tried several frequently applied or newly proposed regularization strategies,
including penalizing weights (embeddings excluded), penalizing embeddings,
re-embedding words, and dropout. We also emphasized on incremental
hyperparameter tuning, and combining different regularizations. The results in
this work provide a picture on tuning hyperparameters for neural NLP.
Author{1}{Firstname}#=%=#Hao
Author{1}{Lastname}#=%=#Peng
Author{1}{Email}#=%=#penghao.pku@gmail.com
Author{1}{Affiliation}#=%=#Peking University
Author{2}{Firstname}#=%=#Lili
Author{2}{Lastname}#=%=#Mou
Author{2}{Email}#=%=#moull12@sei.pku.edu.cn
Author{2}{Affiliation}#=%=#Peking University
Author{3}{Firstname}#=%=#Ge
Author{3}{Lastname}#=%=#Li
Author{3}{Email}#=%=#lige@sei.pku.edu.cn
Author{3}{Affiliation}#=%=#Peking University
Author{4}{Firstname}#=%=#Yunchuan
Author{4}{Lastname}#=%=#Chen
Author{4}{Email}#=%=#yunchuan001@163.com
Author{4}{Affiliation}#=%=#Chinese Academy of Sciences
Author{5}{Firstname}#=%=#Yangyang
Author{5}{Lastname}#=%=#Lu
Author{5}{Email}#=%=#luyy11@sei.pku.edu.cn
Author{5}{Affiliation}#=%=#Peking University
Author{6}{Firstname}#=%=#Zhi
Author{6}{Lastname}#=%=#Jin
Author{6}{Email}#=%=#zhijin@sei.pku.edu.cn
Author{6}{Affiliation}#=%=#Peking University

==========