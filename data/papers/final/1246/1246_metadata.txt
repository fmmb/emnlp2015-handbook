SubmissionNumber#=%=#1246
FinalPaperTitle#=%=#Pre-Computable Multi-Layer Neural Network Language Models
ShortPaperTitle#=%=#Pre-Computable Multi-Layer Neural Network Language Models
NumberOfPages#=%=#5
CopyrightSigned#=%=#Jacob Devlin
JobTitle#==#
Organization#==#Microsoft Research
1 Microsoft Way
Redmond, WA, 98052
Abstract#==#In the last several years, neural network models have significantly improved
accuracy in a number of NLP tasks. However, one serious drawback that has
impeded their adoption in production systems is the slow runtime speed of
neural network models compared to alternate models, such as maximum entropy
classifiers. In Devlin 2014, the authors presented a simple technique for
speeding up
feed-forward embedding-based neural network models, where the dot product
between each word embedding and part of the first hidden layer are pre-computed
offline. However, this technique cannot be used for hidden layers beyond the
first. In this paper, we explore a neural network architecture where the
embedding
layer feeds into multiple hidden layers that are placed ``next to'' one another
so that each can be pre-computed independently. On a large scale language
modeling task, this lateral architecture achieves a 10x speedup at runtime and
a significant reduction in perplexity when compared to a standard multi-layer
network.
Author{1}{Firstname}#=%=#Jacob
Author{1}{Lastname}#=%=#Devlin
Author{1}{Email}#=%=#jdevlin@microsoft.com
Author{1}{Affiliation}#=%=#Microsoft Research
Author{2}{Firstname}#=%=#Chris
Author{2}{Lastname}#=%=#Quirk
Author{2}{Email}#=%=#chrisq@microsoft.com
Author{2}{Affiliation}#=%=#Microsoft Research
Author{3}{Firstname}#=%=#Arul
Author{3}{Lastname}#=%=#Menezes
Author{3}{Email}#=%=#arulm@microsoft.com
Author{3}{Affiliation}#=%=#Microsoft Research

==========